{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "autoencoder_3axes_merged_output.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqG13qPsW7g-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Averaging the results obtained from the models trained on 3 orthogonal axes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmWexsvAXZ7t",
        "colab_type": "code",
        "outputId": "f90f2f5a-879e-4cdc-d056-1f141e0ca0df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Khkz-oH6XaGS",
        "colab_type": "code",
        "outputId": "fb65c471-a8be-4fbb-ac35-9d1df9266e1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "import nibabel as nib #reading MR images\n",
        "import glob\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "!pip install nilearn\n",
        "import nilearn as nil\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nilearn in /usr/local/lib/python3.6/dist-packages (0.5.2)\n",
            "Requirement already satisfied: nibabel>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from nilearn) (2.3.3)\n",
            "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from nibabel>=2.0.2->nilearn) (1.16.3)\n",
            "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from nibabel>=2.0.2->nilearn) (0.98)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from nibabel>=2.0.2->nilearn) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAcKmQnuaJVN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ff = sorted(glob.glob('drive/My Drive/Skull_Stripped_training_input_images/*'))   #For reading a folder\n",
        "N=64    #resized image dimensions (N, N)\n",
        "\n",
        "import cv2\n",
        "images_train = []    #contains the training data sliced over all 3 axes\n",
        "\n",
        "#Have used nibabel library which has been imported as 'nib' to read the Nifti images \n",
        "\n",
        "for f in range(len(ff)):\n",
        "    a = nib.load(ff[f])\n",
        "    a = a.get_fdata()\n",
        "    for k in range(a.shape[0]):                                                                                                   #for k in range(a.shape[0]):\n",
        "        temp = cv2.resize(a[k,:,:], (N, N), interpolation = cv2.INTER_LINEAR)        #INTER_CUBIC  (type of interpolation)                                     #temp = cv2.resize(a[:,100+k,:], (N, N), interpolation = cv2.INTER_CUBIC) \n",
        "        images_train.append(temp)\n",
        "\n",
        "images_train = np.asarray(images_train)  #converting list to a numpy array (first dimension refers to the #of samples and the second and the third are the 2D image dimension)\n",
        "images_train = images_train.reshape(-1,N,N,1)  #-1 is generally used for an unknown dimension\n",
        "\n",
        "m_x = np.max(images_train)    #Normalization over all the training images to get the intensity values between 0 and 1 \n",
        "mi_x = np.min(images_train)\n",
        "\n",
        "images_train_normalized_x = (images_train - mi_x) / (m_x - mi_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3aFQEndaJdA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ff = sorted(glob.glob('drive/My Drive/Skull_Stripped_training_input_images/*'))   #For reading a folder\n",
        "N=64    #resized image dimensions (N, N)\n",
        "\n",
        "import cv2\n",
        "images_train = []    #contains the training data sliced over all 3 axes\n",
        "\n",
        "#Have used nibabel library which has been imported as 'nib' to read the Nifti images \n",
        "\n",
        "for f in range(len(ff)):\n",
        "    a = nib.load(ff[f])\n",
        "    a = a.get_fdata()   \n",
        "    for k in range(a.shape[1]):\n",
        "        temp = cv2.resize(a[:,k,:], (N, N), interpolation = cv2.INTER_LINEAR) \n",
        "        images_train.append(temp)\n",
        "        \n",
        "images_train = np.asarray(images_train)  #converting list to a numpy array (first dimension refers to the #of samples and the second and the third are the 2D image dimension)\n",
        "images_train = images_train.reshape(-1,N,N,1)  #-1 is generally used for an unknown dimension\n",
        "\n",
        "m_y = np.max(images_train)    #Normalization over the ground truth for all the training images to get the intensity values between 0 and 1\n",
        "mi_y = np.min(images_train)\n",
        "\n",
        "images_train_normalized_y = (images_train - mi_y) / (m_y - mi_y)        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46cb5ZjraJnm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ff = sorted(glob.glob('drive/My Drive/Skull_Stripped_training_input_images/*'))   #For reading a folder\n",
        "N=64    #resized image dimensions (N, N)\n",
        "\n",
        "import cv2\n",
        "images_train = []    #contains the training data sliced over all 3 axes\n",
        "\n",
        "#Have used nibabel library which has been imported as 'nib' to read the Nifti images \n",
        "\n",
        "for f in range(len(ff)):\n",
        "    a = nib.load(ff[f])\n",
        "    a = a.get_fdata()   \n",
        "    for k in range(a.shape[2]):\n",
        "        temp = cv2.resize(a[:,:,k], (N, N), interpolation = cv2.INTER_LINEAR) \n",
        "        images_train.append(temp)\n",
        "images_train = np.asarray(images_train)  #converting list to a numpy array (first dimension refers to the #of samples and the second and the third are the 2D image dimension)\n",
        "images_train = images_train.reshape(-1,N,N,1)  #-1 is generally used for an unknown dimension\n",
        "\n",
        "m_z = np.max(images_train)    #Normalization over all the training images to get the intensity values between 0 and 1 \n",
        "mi_z = np.min(images_train)\n",
        "\n",
        "images_train_normalized_z = (images_train - mi_z) / (m_z - mi_z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKXC5Oy3XaOA",
        "colab_type": "code",
        "outputId": "6867a098-85ab-4a08-e929-4bcc94459661",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "from keras.models import load_model #load the model that has been trained previously on 3 orthogonal axes separately\n",
        "\n",
        "model_x = load_model('drive/My Drive/Autoencoder_Models/autoencoder_model_xaxis_epoch50.h5')\n",
        "model_y = load_model('drive/My Drive/Autoencoder_Models/autoencoder_model_yaxis_epoch50.h5')\n",
        "model_z = load_model('drive/My Drive/Autoencoder_Models/autoencoder_model_zaxis_epoch50.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTsC3Uo1XaT4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_x = model_x.predict(images_train_normalized_x)\n",
        "pred_y = model_y.predict(images_train_normalized_y)\n",
        "pred_z = model_z.predict(images_train_normalized_z)\n",
        "\n",
        "# Un-normalizing the data\n",
        "pred_x_unnormalized=(pred_x* (m_x - mi_x) + mi_x)\n",
        "pred_y_unnormalized=(pred_y* (m_y - mi_y) + mi_y)\n",
        "pred_z_unnormalized=(pred_z* (m_z - mi_z) + mi_z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmfDyKcCZxY_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reconstructing bias field on 3 orthogonal axes for one brain volume (can be extended over every volume using a for loop)\n",
        "\n",
        "f=0   #For a single image\n",
        "temp=np.empty([260,311,260])\n",
        "reconstructed_bias_x=[] \n",
        "for idx in range(260*f,260*(f+1)):\n",
        "      img = pred_x_unnormalized[idx, :, :,0]\n",
        "      img_resized = cv2.resize(img, (260, 311), interpolation=cv2.INTER_CUBIC)\n",
        "      temp[idx%260,:,:]=img_resized\n",
        "reconstructed_bias_x.append(temp)\n",
        "\n",
        "f=0   #For a single image\n",
        "temp=np.empty([260,311,260])\n",
        "reconstructed_bias_y=[] \n",
        "for idx in range(311*f,311*(f+1)):\n",
        "      img = pred_y_unnormalized[idx, :, :,0]\n",
        "      img_resized = cv2.resize(img, (260, 260), interpolation=cv2.INTER_CUBIC)\n",
        "      temp[:,idx%311,:]=img_resized\n",
        "reconstructed_bias_y.append(temp)\n",
        "\n",
        "f=0   #For a single image\n",
        "temp=np.empty([260,311,260])\n",
        "reconstructed_bias_z=[] \n",
        "for idx in range(260*f,260*(f+1)):\n",
        "      img = pred_z_unnormalized[idx, :, :,0]\n",
        "      img_resized = cv2.resize(img, (311,260), interpolation=cv2.INTER_CUBIC)\n",
        "      temp[:,:,idx%260]=img_resized\n",
        "reconstructed_bias_z.append(temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwEucwftZxUr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "average_reconstructed_bias=[]\n",
        "#for f in range(len(ff)):\n",
        "#For a single case\n",
        "f=0\n",
        "average_reconstructed_bias.append((reconstructed_bias_x[f] + reconstructed_bias_y[f] + reconstructed_bias_z[f])/3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Td_qbNz2y5ig",
        "colab_type": "code",
        "outputId": "cac581c9-bda0-4ff8-b5e2-550fa87d1e4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(reconstructed_bias_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJgbiRzswil-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ff = sorted(glob.glob('drive/My Drive/Skull_Stripped_training_input_images/*'))   #For reading a folder\n",
        "\n",
        "input_images = []\n",
        "f=0\n",
        "a = nib.load(ff[f])\n",
        "a = a.get_fdata()  \n",
        "input_images.append(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0qneRk-ZxO1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For a single image\n",
        "f=0\n",
        "corrected_images=[]\n",
        "temp=np.empty([260,311,260])\n",
        "for i in range(260):\n",
        "  for j in range(311):\n",
        "    for k in range(260):\n",
        "      if average_reconstructed_bias[f][i,j,k]==0:\n",
        "          temp[i,j,k]=input_images[0][i,j,k]\n",
        "      else:\n",
        "          temp[i,j,k]=input_images[0][i,j,k]/average_reconstructed_bias[f][i,j,k]\n",
        "corrected_images.append(temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSjJRVcYZxGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Corrected MRI images\n",
        "corrected_img = nil.image.new_img_like(nib.load(ff[f]),corrected_images[0],copy_header=True)\n",
        "nib.save(corrected_img,'drive/My Drive/Results/average_corrected_mri.nii.gz')\n",
        "\n",
        "#Estimated bias field\n",
        "reconstructed_img = nil.image.new_img_like(nib.load(ff[f]),average_reconstructed_bias[0],copy_header=True)\n",
        "nib.save(reconstructed_img,'drive/My Drive/Results/average_reconstructed_bias.nii.gz')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rp28QR8lzwoD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}